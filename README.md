# Agentic AI Integration for LMS

# Part -1 (FLASK API) 

"This Flask API allows you to store your course-specific data in a vector database and query it using AI. You can upload PDFs, images, and videos, extract meaningful information, and ask questions based on the stored data. This approach enables an AI-driven agent that provides contextual responses using a conversational retrieval system."


ğŸš€ # Overview

This project provides a Flask-based API that processes PDFs, images, and videos, extracts meaningful data, and enables conversational retrieval using FAISS vector databases and Google Gemini AI. The API supports:

PDF Processing: Extract text and store it in a vector database.

Image Processing: Generate descriptions using Gemini AI.

Video Processing:

Extract audio transcription using Whisper AI.

Generate video descriptions using Gemini AI.

Conversational Retrieval: Ask questions based on stored documents.

ğŸ“‚ #  Project Structure

â”‚â”€â”€ /app

â”‚   â”œâ”€â”€ __init__.py          # Initializes Flask app

â”‚   â”œâ”€â”€ config.py            # API Key Configuration


â”‚   â”œâ”€â”€ routes.py            # Defines Flask API routes

â”‚   â”œâ”€â”€ utils.py             # Helper functions (image, audio, video processing)

â”‚   â”œâ”€â”€ vectorstore.py       # FAISS vector database management

â”‚â”€â”€ main.py                  # Entry point

â”‚â”€â”€ requirements.txt         # Dependencies

â”‚â”€â”€ README.md                # Documentation

Run the Flask Server

python main.py

ğŸ“Œ API Endpoints

# Upload PDF

Endpoint: POST /upload_pdf

Description: Extracts text from PDFs and stores it in FAISS.

Request:  curl -X POST -F "files=@sample.pdf" http://localhost:8000/upload_pdf

# Upload Image

Endpoint: POST /upload_image

Description: Generates an AI-powered description of the uploaded image.

Request:  curl -X POST -F "file=@image.jpg" http://localhost:8000/upload_image


{
  "description": "A beautiful sunset over the mountains.",
  "message": "Image description stored in vector database."
}

# Upload Video

Endpoint: POST /upload_video

Description: Extracts audio transcription or video description.

Request:  curl -X POST -F "file=@video.mp4" -F "option=Transcription" http://localhost:8000/upload_video



{
  "result": "This video is about AI and machine learning...",
  "message": "Video description stored in vector database."
}

ğŸ”¹ Ask a Question

Endpoint: POST /ask_question

Description: Queries stored data and retrieves relevant responses.

Request:

curl -X POST -H "Content-Type: application/json" -d '{"question": "What is the content of the PDF?"}' http://localhost:8000/ask_question

 # Technologies Used

Flask (Backend API)

Google Gemini AI (Image & Video Descriptions, Conversational AI)

FAISS (Vector Database for Text Search)

Whisper AI (Audio Transcription)

PyPDF2 (PDF Text Extraction)

MoviePy (Audio Extraction from Video)



![Screenshot 2025-04-02 162110](https://github.com/user-attachments/assets/f82d9086-dceb-49e8-aa95-07bf1e836765)

![Screenshot 2025-04-02 162125](https://github.com/user-attachments/assets/cf786026-9229-4614-9c66-cde80485410c)


# Part -2 ( streamlit interface) 

# headline - Agentic AI Integration for LMSs ğŸ“„ğŸ¥ğŸ–¼ï¸

This is a **Streamlit-based AI-powered app** that allows users to interact with PDFs, videos, and images using **Google Gemini AI, Whisper, FAISS, and LangChain**.

## ğŸš€ Features
- ğŸ“„ **PDF Processing**: Extracts text from PDFs and enables conversational interaction.
- ğŸ¥ **Video Processing**: Supports **speech-to-text transcription** and **video description**.
- ğŸ–¼ï¸ **Image Analysis**: Generates descriptions for uploaded images.
- ğŸ§  **Conversational AI**: Uses **Gemini AI** for intelligent responses.
- ğŸ” **Semantic Search**: Uses **FAISS vector store** to retrieve relevant information.

---
# Run the App

streamlit run main.py

#ğŸ“‚ Project Structure



â”‚â”€â”€ ğŸ“„ main_2.py                 # Streamlit app entry point

â”‚â”€â”€ ğŸ“„ config.py               # Configuration settings

â”‚â”€â”€ ğŸ“‚ modules/

â”‚   â”‚â”€â”€ ğŸ“„ pdf_processing.py    # PDF text extraction

â”‚   â”‚â”€â”€ ğŸ“„ video_processing.py  # Video transcription & description

â”‚   â”‚â”€â”€ ğŸ“„ image_processing.py  # Image description

â”‚   â”‚â”€â”€ ğŸ“„ ai_services.py       # AI models (Gemini, Whisper)

â”‚   â”‚â”€â”€ ğŸ“„ vectorstore.py       # FAISS vector store

â”‚   â”‚â”€â”€ ğŸ“„ chat.py              # Conversational AI logic

â”‚â”€â”€ ğŸ“„ requirements.txt        # Dependencies

â”‚â”€â”€ ğŸ“„ .env                    # API keys

â”‚â”€â”€ ğŸ“„ README.md               # Documentation

# ğŸ“Œ How It Works


Upload PDFs, videos, or images via the sidebar.

Choose transcription or description for videos.

The app processes the content and generates responses.

Ask questions in the chat about the uploaded documents.

# Install Dependencies

pip install -r requirements.txt

# Set Up Environment Variables

GOOGLE_API_KEY=your_google_api_key_here
